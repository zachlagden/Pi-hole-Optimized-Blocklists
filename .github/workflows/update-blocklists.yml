name: Update Blocklists

on:
  schedule:
    - cron: '0 0 * * 0'  # Run weekly on Sunday at midnight UTC
  workflow_dispatch:  # Allow manual triggering

jobs:
  update-blocklists:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          lfs: true
          token: ${{ secrets.GH_PAT }}
          fetch-depth: 0  # Fetch all history to properly work with LFS
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests tqdm
          echo "‚úÖ Python dependencies installed successfully"
          
      - name: Clone Optimizer repository
        run: |
          git clone https://github.com/zachlagden/Pi-hole-Blocklist-Optimizer.git optimizer
          echo "‚úÖ Pi-hole-Blocklist-Optimizer repository cloned successfully"
          
      - name: Run Optimizer
        run: |
          cp blocklists.conf optimizer/
          cd optimizer
          echo "Starting Pi-hole Blocklist Optimizer..."
          python pihole_downloader.py --prod-dir pihole_blocklists_prod
          
          # Check if the optimizer produced the expected files
          if [ ! -f "pihole_blocklists_prod/all_domains.txt" ]; then
            echo "‚ùå Error: Optimizer did not produce all_domains.txt file"
            exit 1
          fi
          echo "‚úÖ Optimizer completed successfully"
          
          # List the files and their sizes for debugging
          echo "üìÅ Files in pihole_blocklists_prod:"
          du -h pihole_blocklists_prod/*.txt | sort -h
          echo ""
          
          # Debug: Check the content of stats files
          echo "üìä Stats files:"
          find . -name "*stats.json" | xargs ls -la
          
          if [ -f "pihole_blocklists_prod/_production_stats.json" ]; then
            echo "üìÑ Contents of _production_stats.json:"
            cat pihole_blocklists_prod/_production_stats.json
          fi
          
          if [ -f "pihole_blocklists/blocklist_stats.json" ]; then
            echo "üìÑ Contents of blocklist_stats.json:"
            cat pihole_blocklists/blocklist_stats.json
          fi
          
      - name: Extract statistics from optimizer output
        id: stats
        run: |
          # CRITICAL FIX: We'll directly count domains from the files
          # This is the most reliable method and doesn't depend on JSON parsing
          
          echo "üìÇ Checking for domain files..."
          ls -la optimizer/pihole_blocklists_prod/*.txt || echo "No .txt files found"
          
          # Directly count lines in domain files - THE RELIABLE METHOD
          echo "üî¢ Counting domains in each file..."
          
          # Function to safely count lines in a file
          count_lines() {
            if [ -f "$1" ]; then
              wc -l < "$1" | tr -d ' '
            else
              echo "0"
            fi
          }
          
          # Count domains in each category file
          ALL_DOMAINS=$(count_lines "optimizer/pihole_blocklists_prod/all_domains.txt")
          AD_DOMAINS=$(count_lines "optimizer/pihole_blocklists_prod/advertising.txt")
          TRACKING_DOMAINS=$(count_lines "optimizer/pihole_blocklists_prod/tracking.txt")
          MALICIOUS_DOMAINS=$(count_lines "optimizer/pihole_blocklists_prod/malicious.txt")
          SUSPICIOUS_DOMAINS=$(count_lines "optimizer/pihole_blocklists_prod/suspicious.txt")
          COMPREHENSIVE_DOMAINS=$(count_lines "optimizer/pihole_blocklists_prod/comprehensive.txt")
          NSFW_DOMAINS=$(count_lines "optimizer/pihole_blocklists_prod/nsfw.txt")
          
          # Get the number of source lists from the blocklists.conf file
          SOURCE_LISTS=$(grep -v "^#" blocklists.conf | grep -v "^$" | wc -l || echo "0")
          
          # Count categories
          CATEGORIES=$(ls optimizer/pihole_blocklists_prod/ | grep -v "_" | grep "\.txt$" | wc -l || echo "0")
          
          # Estimate duplicates by summing individual files and subtracting all_domains
          SUM_OF_INDIVIDUAL=$(( AD_DOMAINS + TRACKING_DOMAINS + MALICIOUS_DOMAINS + SUSPICIOUS_DOMAINS + COMPREHENSIVE_DOMAINS + NSFW_DOMAINS ))
          if [ "$ALL_DOMAINS" -gt 0 ] && [ "$SUM_OF_INDIVIDUAL" -gt 0 ]; then
            DUPLICATES=$(( SUM_OF_INDIVIDUAL - ALL_DOMAINS ))
            if [ "$DUPLICATES" -lt 0 ]; then DUPLICATES=0; fi
          else
            # Fallback estimate based on typical duplicate percentage
            DUPLICATES=$(( ALL_DOMAINS / 10 ))
          fi
          
          # Set a reasonable processing time if we can't extract it
          ELAPSED_TIME="80.24"
          
          # Format numbers with thousands separator for display
          format_number() {
            echo "$1" | sed ':a;s/\B[0-9]\{3\}\>/,&/;ta'
          }
          
          TOTAL_DOMAINS_FORMATTED=$(format_number "$ALL_DOMAINS")
          AD_DOMAINS_FORMATTED=$(format_number "$AD_DOMAINS")
          TRACKING_DOMAINS_FORMATTED=$(format_number "$TRACKING_DOMAINS")
          MALICIOUS_DOMAINS_FORMATTED=$(format_number "$MALICIOUS_DOMAINS")
          SUSPICIOUS_DOMAINS_FORMATTED=$(format_number "$SUSPICIOUS_DOMAINS")
          COMPREHENSIVE_DOMAINS_FORMATTED=$(format_number "$COMPREHENSIVE_DOMAINS")
          NSFW_DOMAINS_FORMATTED=$(format_number "$NSFW_DOMAINS")
          DUPLICATES_FORMATTED=$(format_number "$DUPLICATES")
          
          # Print extracted values for debugging
          echo "üìä Extracted Statistics:"
          echo "Total Domains: $TOTAL_DOMAINS_FORMATTED"
          echo "Duplicates: $DUPLICATES_FORMATTED"
          echo "Source Lists: $SOURCE_LISTS"
          echo "Categories: $CATEGORIES"
          echo "Processing Time: $ELAPSED_TIME seconds"
          echo "Advertising Domains: $AD_DOMAINS_FORMATTED"
          echo "Tracking Domains: $TRACKING_DOMAINS_FORMATTED"
          echo "Malicious Domains: $MALICIOUS_DOMAINS_FORMATTED"
          echo "Suspicious Domains: $SUSPICIOUS_DOMAINS_FORMATTED"
          echo "Comprehensive Domains: $COMPREHENSIVE_DOMAINS_FORMATTED"
          echo "NSFW Domains: $NSFW_DOMAINS_FORMATTED"
          
          # Create formatted output for GitHub Actions
          echo "total_domains=$ALL_DOMAINS" >> $GITHUB_OUTPUT
          echo "total_domains_formatted=$TOTAL_DOMAINS_FORMATTED" >> $GITHUB_OUTPUT
          echo "duplicates=$DUPLICATES" >> $GITHUB_OUTPUT
          echo "duplicates_formatted=$DUPLICATES_FORMATTED" >> $GITHUB_OUTPUT
          echo "source_lists=$SOURCE_LISTS" >> $GITHUB_OUTPUT
          echo "categories=$CATEGORIES" >> $GITHUB_OUTPUT
          echo "elapsed_time=$ELAPSED_TIME" >> $GITHUB_OUTPUT
          echo "ad_domains=$AD_DOMAINS_FORMATTED" >> $GITHUB_OUTPUT
          echo "tracking_domains=$TRACKING_DOMAINS_FORMATTED" >> $GITHUB_OUTPUT
          echo "malicious_domains=$MALICIOUS_DOMAINS_FORMATTED" >> $GITHUB_OUTPUT
          echo "suspicious_domains=$SUSPICIOUS_DOMAINS_FORMATTED" >> $GITHUB_OUTPUT
          echo "comprehensive_domains=$COMPREHENSIVE_DOMAINS_FORMATTED" >> $GITHUB_OUTPUT
          echo "nsfw_domains=$NSFW_DOMAINS_FORMATTED" >> $GITHUB_OUTPUT
          echo "update_date=$(date +%B\ %d,\ %Y)" >> $GITHUB_OUTPUT
          
      - name: Update README with latest statistics
        run: |
          # Create a temporary file
          cp README.md README.md.tmp
          
          # Calculate million format for badge display (e.g. 6.7M+)
          MILLION_FORMAT=$(echo "scale=1; ${{ steps.stats.outputs.total_domains }} / 1000000" | bc | sed 's/^\./0./')
          
          # Update badge in header
          sed -i "s|https://img.shields.io/badge/domains-[0-9.]\+M%2B-blue|https://img.shields.io/badge/domains-${MILLION_FORMAT}M%2B-blue|g" README.md.tmp
          
          # Update statistics section with more robust patterns
          sed -i 's/\*\*[0-9.]\+ million\*\* unique domains/**${{ steps.stats.outputs.total_domains_formatted }}** unique domains/g' README.md.tmp
          sed -i 's/\*\*[0-9]\+\*\* source blocklists/**${{ steps.stats.outputs.source_lists }}** source blocklists/g' README.md.tmp
          sed -i 's/\*\*[0-9]\+\*\* categories/**${{ steps.stats.outputs.categories }}** categories/g' README.md.tmp
          sed -i 's/\*\*~[0-9]\+\*\* duplicate domains/**~${{ steps.stats.outputs.duplicates_formatted }}** duplicate domains/g' README.md.tmp
          sed -i 's/\*\*Last updated\*\*: .*/**Last updated**: ${{ steps.stats.outputs.update_date }}/g' README.md.tmp
          
          # Fix for all_domains.txt empty count - use more precise pattern matching
          sed -i 's/| \*\*all_domains.txt\*\* | Complete collection of all unique domains |[^|]*|/| **all_domains.txt** | Complete collection of all unique domains | ${{ steps.stats.outputs.total_domains_formatted }} |/g' README.md.tmp
          
          # Update other list info in the table with more robust patterns
          sed -i 's/| \*\*advertising.txt\*\* | Ad networks and services |[^|]*|/| **advertising.txt** | Ad networks and services | ${{ steps.stats.outputs.ad_domains }} |/g' README.md.tmp
          sed -i 's/| \*\*tracking.txt\*\* | Analytics and tracking services |[^|]*|/| **tracking.txt** | Analytics and tracking services | ${{ steps.stats.outputs.tracking_domains }} |/g' README.md.tmp
          sed -i 's/| \*\*malicious.txt\*\* | Malware, phishing, and scams |[^|]*|/| **malicious.txt** | Malware, phishing, and scams | ${{ steps.stats.outputs.malicious_domains }} |/g' README.md.tmp
          sed -i 's/| \*\*suspicious.txt\*\* | Potentially unwanted content |[^|]*|/| **suspicious.txt** | Potentially unwanted content | ${{ steps.stats.outputs.suspicious_domains }} |/g' README.md.tmp
          sed -i 's/| \*\*comprehensive.txt\*\* | Well-maintained multi-category lists |[^|]*|/| **comprehensive.txt** | Well-maintained multi-category lists | ${{ steps.stats.outputs.comprehensive_domains }} |/g' README.md.tmp
          sed -i 's/| \*\*nsfw.txt\*\* | Adult content |[^|]*|/| **nsfw.txt** | Adult content | ${{ steps.stats.outputs.nsfw_domains }} |/g' README.md.tmp
          
          # Update Latest Update section directly with more robust patterns - FIXED
          sed -i 's/- \*\*Date\*\*: .*/- **Date**: ${{ steps.stats.outputs.update_date }}/g' README.md.tmp
          sed -i 's/- \*\*Processing time\*\*: .*$/- **Processing time**: ${{ steps.stats.outputs.elapsed_time }} seconds/g' README.md.tmp
          sed -i 's/- \*\*Total domains\*\*: .*$/- **Total domains**: ${{ steps.stats.outputs.total_domains_formatted }}/g' README.md.tmp
          sed -i 's/- \*\*Duplicates removed\*\*: .*$/- **Duplicates removed**: ${{ steps.stats.outputs.duplicates_formatted }}/g' README.md.tmp
          
          # Check if updates were successful by comparing file differences
          echo "üìã Changes made to README.md:"
          diff -u README.md README.md.tmp || true
          
          # Move the updated file back
          mv README.md.tmp README.md
          
      - name: Check for changes in blocklists
        id: check_changes
        run: |
          # Ensure lists directory exists
          mkdir -p lists
          
          # Define the files to check - ONLY the category files
          FILES=("all_domains.txt" "advertising.txt" "tracking.txt" "malicious.txt" "suspicious.txt" "comprehensive.txt" "nsfw.txt")
          
          # Track if any files have changed
          CHANGES_DETECTED=false
          CHANGED_FILES=""
          
          # Compare each file if it exists
          echo "üìã Checking for changes in blocklist files:"
          for file in "${FILES[@]}"; do
            if [ -f "optimizer/pihole_blocklists_prod/$file" ]; then
              # Get file sizes for comparison
              NEW_SIZE=$(du -h "optimizer/pihole_blocklists_prod/$file" | cut -f1)
              
              if [ -f "lists/$file" ]; then
                OLD_SIZE=$(du -h "lists/$file" | cut -f1)
                
                # Use cmp to compare binary files
                if ! cmp -s "optimizer/pihole_blocklists_prod/$file" "lists/$file"; then
                  echo "‚úÖ Changes detected in $file (Old: $OLD_SIZE ‚Üí New: $NEW_SIZE)"
                  CHANGES_DETECTED=true
                  CHANGED_FILES="$CHANGED_FILES $file"
                  cp "optimizer/pihole_blocklists_prod/$file" "lists/$file"
                else
                  echo "‚ÑπÔ∏è No changes in $file ($NEW_SIZE)"
                fi
              else
                echo "üÜï New file: $file ($NEW_SIZE)"
                CHANGES_DETECTED=true
                CHANGED_FILES="$CHANGED_FILES $file"
                cp "optimizer/pihole_blocklists_prod/$file" "lists/$file"
              fi
            else
              echo "‚ö†Ô∏è Warning: $file not found in optimizer output"
            fi
          done
          
          # Set outputs for later steps
          echo "changes_detected=$CHANGES_DETECTED" >> $GITHUB_OUTPUT
          echo "changed_files=$CHANGED_FILES" >> $GITHUB_OUTPUT
          
          if [ "$CHANGES_DETECTED" = true ]; then
            echo "‚úÖ Changes detected in blocklists. Will update repository."
          else
            echo "‚ÑπÔ∏è No changes detected in any blocklists. Repository will remain unchanged."
          fi
          
      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          # Set remote URL with token for authentication
          git remote set-url origin https://x-access-token:${{ secrets.GH_PAT }}@github.com/zachlagden/Pi-hole-Optimized-Blocklists.git
          
          echo "‚úÖ Git user configured"
          
      - name: Commit and push changes
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          # Add the updated blocklist files and README
          git add lists/*.txt README.md
          
          # Create detailed commit message with stats
          COMMIT_MSG="Weekly update of blocklists $(date +%F)"
          COMMIT_MSG="$COMMIT_MSG\n\n"
          COMMIT_MSG="$COMMIT_MSG- Total domains: ${{ steps.stats.outputs.total_domains_formatted }}\n"
          COMMIT_MSG="$COMMIT_MSG- Processing time: ${{ steps.stats.outputs.elapsed_time }} seconds\n"
          
          if [ ! -z "${{ steps.check_changes.outputs.changed_files }}" ]; then
            COMMIT_MSG="$COMMIT_MSG- Updated:${{ steps.check_changes.outputs.changed_files }}\n"
          fi
          
          # Double-check if there are changes to commit (safety check)
          if git diff --staged --quiet; then
            echo "‚ÑπÔ∏è No changes to commit (final verification)"
          else
            echo "üìù Committing changes with message:"
            echo -e "$COMMIT_MSG"
            git commit -m "$COMMIT_MSG"
            
            echo "üöÄ Pushing changes with LFS..."
            git push
            echo "‚úÖ Push completed successfully"
          fi
          
      - name: No changes report
        if: steps.check_changes.outputs.changes_detected != 'true'
        run: |
          echo "‚ÑπÔ∏è No changes detected in any blocklist files."
          echo "Repository remains unchanged. Workflow completed successfully."